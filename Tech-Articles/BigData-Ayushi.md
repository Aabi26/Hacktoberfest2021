
=======================================================

Article Title: Big Data
Author Name: Ayushi Pal
Author Profile: https://github.com/ayushipal671
Date: 15-10-21

=======================================================
What is Big Data?
Big Data is a collection of data that is huge in volume, yet growing exponentially with time. It is a data with so large size and complexity that none of traditional data
management tools can store it or process it efficiently. Example- The statistic shows that 500+ terabytes of new data get ingested into the databases of social media site
Facebook, every day. This data is mainly generated in terms of photo and video uploads, message exchanges, putting comments etc.

Types Of Big Data:
(i)  Structured- Any data that can be stored, accessed and processed in the form of fixed format is termed as a ‘structured’ data. Over the period of time, talent in computer
science has achieved greater success in developing techniques for working with such kind of data (where the format is well known in advance) and also deriving value out of it. 
However, nowadays, we are foreseeing issues when a size of such data grows to a huge extent, typical sizes are being in the rage of multiple zettabytes.
(ii) Unstructured- Any data with unknown form or the structure is classified as unstructured data. In addition to the size being huge, un-structured data poses multiple
challenges in terms of its processing for deriving value out of it. A typical example of unstructured data is a heterogeneous data source containing a combination of simple 
text files, images, videos etc. Nowadays, organizations have wealth of data available with them but unfortunately, they don’t know how to derive value out of it since this data
is in its raw form or unstructured format.
(iii) Semi-structured- Semi-structured data can contain both the forms of data. We can see semi-structured data as a structured in form but it is actually not defined with e.g.
a table definition in relational DBMS. 

Characteristics Of Big Data:
(i) Volume – The name Big Data itself is related to a size which is enormous. Size of data plays a very crucial role in determining value out of data. Also, whether a particular
data can actually be considered as a Big Data or not, is dependent upon the volume of data. Hence, ‘Volume’ is one characteristic which needs to be considered while dealing 
with Big Data solutions.
(ii) Variety – The next aspect of Big Data is its variety. Variety refers to heterogeneous sources and the nature of data, both structured and unstructured. During earlier days
, spreadsheets and databases were the only sources of data considered by most of the applications. Nowadays, data in the form of emails, photos, videos, monitoring devices, PDFs,
audio, etc. are also being considered in the analysis applications. This variety of unstructured data poses certain issues for storage, mining and analyzing data.
(iii) Velocity – The term ‘velocity’ refers to the speed of generation of data. How fast the data is generated and processed to meet the demands, determines real potential in 
the data.Big Data Velocity deals with the speed at which data flows in from sources like business processes, application logs, networks, and social media sites, sensors, Mobile
devices, etc.The flow of data is massive and continuous.
(iv) Variability – This refers to the inconsistency which can be shown by the data at times, thus hampering the process of being able to handle and manage the data effectively.



